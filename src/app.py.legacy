import sys
import os
import re
import json
from pathlib import Path
import importlib

# Ensure repository root is on sys.path so `src` can be imported when running
# `streamlit run src/app.py` from the project root.
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

from src.backtest import run_backtest_for_ui
# NOTE: TWS/ib_insync ingestion is triggered via a subprocess CLI call from the
# Data tab to avoid event-loop issues in the Streamlit runtime.
from src.data_processing import (
    clean_raw_minute_data,
    convert_minute_to_timeframe,
    prepare_keras_input_data,
)
from src.data import load_hourly_ohlc

# Use wide layout so plots can take full screen width.
st.set_page_config(layout="wide")
import src.config as cfg_mod
from src.train import train_model
from src.config import (
    FREQUENCY,
    TSTEPS,
    RESAMPLE_FREQUENCIES,
    TSTEPS_OPTIONS,
    LSTM_UNITS_OPTIONS,
    BATCH_SIZE_OPTIONS,
    N_LSTM_LAYERS_OPTIONS,
    STATEFUL_OPTIONS,
    FEATURES_TO_USE_OPTIONS,
    MODEL_REGISTRY_DIR,
    get_run_hyperparameters,
    get_predictions_csv_path,
)
from scripts.generate_predictions_csv import generate_predictions_for_csv

# Shared frequency across tabs, defaulting to 60min when available.
if "global_frequency" not in st.session_state:
    if "60min" in RESAMPLE_FREQUENCIES:
        st.session_state["global_frequency"] = "60min"
    else:
        st.session_state["global_frequency"] = FREQUENCY

CONFIG_PATH = Path(__file__).with_name("config.py")
PARAMS_STATE_PATH = Path(__file__).with_name("ui_strategy_params.json")

# Import UI helpers from new modules
from src.ui.state import (
    get_ui_state as _get_ui_state,
    load_history as _load_json_history,
    save_history as _save_json_history,
    MAX_HISTORY_ROWS,
)
from src.ui.formatting import (
    format_timestamp as _format_timestamp_iso_seconds,
    filter_training_history as _filter_training_history,
    filter_backtest_history as _filter_backtest_history,
    filter_optimization_history as _filter_optimization_history,
    get_best_training_row as _get_best_training_row,
)
from src.ui.registry import (
    list_registry_models as _list_registry_models,
    promote_training_row as _promote_training_row,
)


def _load_strategy_defaults() -> dict:
    """Return effective strategy defaults from config_resolver.

    Merges code defaults (config.py) with user overrides (configs/active.json).
    The resolver provides the single source of truth for strategy parameters.
    """
    from src.core.config_resolver import get_strategy_defaults

    # Still reload config module for callers that reference cfg_mod.
    module_name = "src.config"
    module = sys.modules.get(module_name)
    if module is not None:
        module = importlib.reload(module)
    else:
        module = importlib.import_module(module_name)

    global cfg_mod
    cfg_mod = module

    # Get merged defaults from config_resolver.
    defaults = get_strategy_defaults()

    # Add backwards-compatible aliases for legacy code.
    defaults["k_sigma_err"] = defaults["k_sigma_long"]
    defaults["k_atr_min_tp"] = defaults["k_atr_long"]

    return defaults


def _build_default_params_df(defaults: dict) -> pd.DataFrame:
    """Return the default parameter grid based on current config defaults."""

    return pd.DataFrame(
        [
            {
                "Parameter": "k_sigma_long",
                "Value": defaults["k_sigma_long"],
                "Start": defaults["k_sigma_long"],
                "Step": 0.1,
                "Stop": defaults["k_sigma_long"],
                "Optimize": True,
            },
            {
                "Parameter": "k_sigma_short",
                "Value": defaults["k_sigma_short"],
                "Start": defaults["k_sigma_short"],
                "Step": 0.1,
                "Stop": defaults["k_sigma_short"],
                "Optimize": True,
            },
            {
                "Parameter": "k_atr_long",
                "Value": defaults["k_atr_long"],
                "Start": defaults["k_atr_long"],
                "Step": 0.1,
                "Stop": defaults["k_atr_long"],
                "Optimize": False,
            },
            {
                "Parameter": "k_atr_short",
                "Value": defaults["k_atr_short"],
                "Start": defaults["k_atr_short"],
                "Step": 0.1,
                "Stop": defaults["k_atr_short"],
                "Optimize": False,
            },
            {
                "Parameter": "risk_per_trade_pct",
                "Value": defaults["risk_per_trade_pct"],
                "Start": defaults["risk_per_trade_pct"],
                "Step": 0.001,
                "Stop": defaults["risk_per_trade_pct"],
                "Optimize": False,
            },
            {
                "Parameter": "reward_risk_ratio",
                "Value": defaults["reward_risk_ratio"],
                "Start": defaults["reward_risk_ratio"],
                "Step": 0.1,
                "Stop": defaults["reward_risk_ratio"],
                "Optimize": False,
            },
        ]
    )


def _load_params_grid(defaults: dict) -> pd.DataFrame:
    """Load the parameter grid from disk, falling back to defaults.

    This persists Value/Start/Step/Stop/Optimize across UI reloads, while
    still using config.py defaults when the state file does not exist.
    """

    if PARAMS_STATE_PATH.exists():
        try:
            raw = PARAMS_STATE_PATH.read_text(encoding="utf-8")
            records = json.loads(raw)
            if isinstance(records, list) and records:
                df = pd.DataFrame(records)
                # Ensure all required columns exist; fill missing with defaults.
                required_cols = {"Parameter", "Value", "Start", "Step", "Stop", "Optimize"}
                missing = required_cols - set(df.columns)
                if missing:
                    # Merge with a fresh default df as a template.
                    base = _build_default_params_df(defaults)
                    df = pd.merge(
                        base,
                        df,
                        on="Parameter",
                        how="left",
                        suffixes=("_base", ""),
                    )
                    # Prefer loaded values when present; otherwise use base.
                    rows = []
                    for _, row in df.iterrows():
                        name = row["Parameter"]
                        base_row = base[base["Parameter"] == name].iloc[0]

                        value = row.get("Value", base_row["Value"])
                        if pd.isna(value):
                            value = base_row["Value"]

                        start = row.get("Start", base_row["Start"])
                        if pd.isna(start):
                            start = base_row["Start"]

                        step = row.get("Step", base_row["Step"])
                        if pd.isna(step):
                            step = base_row["Step"]

                        stop = row.get("Stop", base_row["Stop"])
                        if pd.isna(stop):
                            stop = base_row["Stop"]

                        optimize_val = row.get("Optimize", base_row["Optimize"])
                        if pd.isna(optimize_val):
                            optimize_val = base_row["Optimize"]

                        rows.append(
                            {
                                "Parameter": name,
                                "Value": value,
                                "Start": start,
                                "Step": step,
                                "Stop": stop,
                                "Optimize": bool(optimize_val),
                            }
                        )
                    df = pd.DataFrame(rows)
                return df
        except Exception:
            # Fall back to defaults on any parse error.
            pass

    return _build_default_params_df(defaults)


def _save_params_grid(df: pd.DataFrame | object) -> None:
    """Persist the full parameter grid (Value/Start/Step/Stop/Optimize).

    Be defensive about the input type: older session_state entries or callers
    might pass a list/dict instead of a DataFrame.
    """

    try:
        if not isinstance(df, pd.DataFrame):
            df = pd.DataFrame(df)
        records = df.to_dict(orient="records")
        PARAMS_STATE_PATH.write_text(json.dumps(records, indent=2), encoding="utf-8")
    except Exception as exc:  # pragma: no cover - best-effort persistence
        st.error(f"Failed to save parameter grid: {exc}")


def _save_strategy_defaults_to_config(
    *,
    risk_per_trade_pct: float,
    reward_risk_ratio: float,
    k_sigma_long: float,
    k_sigma_short: float,
    k_atr_long: float,
    k_atr_short: float,
) -> None:
    """Persist current strategy parameters to configs/active.json.

    Does NOT edit src/config.py (which remains read-only for the UI).
    User overrides are stored in configs/active.json and merged with code
    defaults at runtime by the config_resolver.
    """
    from src.core.config_resolver import save_strategy_defaults

    try:
        save_strategy_defaults(
            risk_per_trade_pct=risk_per_trade_pct,
            reward_risk_ratio=reward_risk_ratio,
            k_sigma_long=k_sigma_long,
            k_sigma_short=k_sigma_short,
            k_atr_long=k_atr_long,
            k_atr_short=k_atr_short,
        )
    except Exception as exc:  # pragma: no cover - best-effort persistence
        st.error(f"Failed to save strategy defaults to configs/active.json: {exc}")


def _run_backtest(
    frequency: str,
    start_date: str | None,
    end_date: str | None,
    risk_per_trade_pct: float | None,
    reward_risk_ratio: float | None,
    k_sigma_long: float | None,
    k_sigma_short: float | None,
    k_atr_long: float | None,
    k_atr_short: float | None,
    enable_longs: bool | None,
    allow_shorts: bool | None,
):
    """Non-cached wrapper around run_backtest_for_ui (CSV mode by default).

    The UI uses precomputed per-bar predictions (CSV mode) for backtests by
    default, which is simpler and more robust for experiments.
    """

    from src.config import get_predictions_csv_path as _get_predictions_csv_path

    predictions_csv = _get_predictions_csv_path("nvda", frequency)
    if predictions_csv and not os.path.exists(predictions_csv):
        raise FileNotFoundError(
            f"Predictions CSV not found: '{predictions_csv}'. "
            "Use the 'Generate predictions CSV for NVDA' button first."
        )

    return run_backtest_for_ui(
        frequency=frequency,
        prediction_mode="csv",
        start_date=start_date,
        end_date=end_date,
        predictions_csv=predictions_csv,
        risk_per_trade_pct=risk_per_trade_pct,
        reward_risk_ratio=reward_risk_ratio,
        k_sigma_err=None,
        k_atr_min_tp=None,
        k_sigma_long=k_sigma_long,
        k_sigma_short=k_sigma_short,
        k_atr_long=k_atr_long,
        k_atr_short=k_atr_short,
        enable_longs=enable_longs,
        allow_shorts=allow_shorts,
    )


def _set_optimization_running(is_running: bool) -> None:
    # Used to prevent Live-tab auto-refresh from interrupting long-running
    # optimization runs.
    st.session_state["optimization_running"] = bool(is_running)


def _start_optimization() -> None:
    _set_optimization_running(True)


def _stop_optimization() -> None:
    _set_optimization_running(False)


st.title("LSTM Backtesting & Training UI")

# Six main tabs matching the end-to-end workflow.
# "Live" is intended to be the primary operational dashboard during market hours.
tab_live, tab_data, tab_experiments, tab_train, tab_backtest, tab_walkforward = st.tabs(
    [
        "Live",
        "Data",
        "Hyperparameter Experiments",
        "Train & Promote",
        "Backtest / Strategy",
        "Walk-Forward Analysis",
    ]
)

# --------------------------------------------------------------------------------------
# Tab 0: Live - operational dashboard (Step 1: log-derived KPIs + recent events)
# --------------------------------------------------------------------------------------
with tab_live:
    from src.ui.pages import live_page

    live_page.render_live_tab(
        st=st,
        pd=pd,
        plt=plt,
    )

# --------------------------------------------------------------------------------------
# Tab 1: Data - ingestion, cleaning, resampling, and feature preview
# --------------------------------------------------------------------------------------
with tab_data:
    from src.ui.pages import data_page

    data_page.render_data_tab(
        st=st,
        pd=pd,
        os=os,
        Path=Path,
        project_root=Path(__file__).resolve().parents[1],
        RESAMPLE_FREQUENCIES=RESAMPLE_FREQUENCIES,
        FREQUENCY=FREQUENCY,
        clean_raw_minute_data=clean_raw_minute_data,
        convert_minute_to_timeframe=convert_minute_to_timeframe,
        prepare_keras_input_data=prepare_keras_input_data,
    )
# --------------------------------------------------------------------------------------
# Tab 2: Hyperparameter Experiments - short runs, no promotion
# --------------------------------------------------------------------------------------
with tab_experiments:
    from src.ui.pages import experiments_page

    experiments_page.render_experiments_tab(
        st=st,
        pd=pd,
        os=os,
        train_model=train_model,
        FREQUENCY=FREQUENCY,
        TSTEPS=TSTEPS,
        RESAMPLE_FREQUENCIES=RESAMPLE_FREQUENCIES,
        TSTEPS_OPTIONS=TSTEPS_OPTIONS,
        LSTM_UNITS_OPTIONS=LSTM_UNITS_OPTIONS,
        N_LSTM_LAYERS_OPTIONS=N_LSTM_LAYERS_OPTIONS,
        BATCH_SIZE_OPTIONS=BATCH_SIZE_OPTIONS,
        STATEFUL_OPTIONS=STATEFUL_OPTIONS,
        FEATURES_TO_USE_OPTIONS=FEATURES_TO_USE_OPTIONS,
        MAX_HISTORY_ROWS=MAX_HISTORY_ROWS,
        get_run_hyperparameters=get_run_hyperparameters,
        get_ui_state=_get_ui_state,
        load_json_history=_load_json_history,
        save_json_history=_save_json_history,
    )
# --------------------------------------------------------------------------------------
# Tab 3: Train & Promote - iterative runs + explicit promotion
# --------------------------------------------------------------------------------------
with tab_train:
    from src.ui.pages import train_page

    train_page.render_train_tab(
        st=st,
        pd=pd,
        json=json,
        Path=Path,
        os=os,
        FREQUENCY=FREQUENCY,
        TSTEPS=TSTEPS,
        RESAMPLE_FREQUENCIES=RESAMPLE_FREQUENCIES,
        TSTEPS_OPTIONS=TSTEPS_OPTIONS,
        LSTM_UNITS_OPTIONS=LSTM_UNITS_OPTIONS,
        N_LSTM_LAYERS_OPTIONS=N_LSTM_LAYERS_OPTIONS,
        BATCH_SIZE_OPTIONS=BATCH_SIZE_OPTIONS,
        STATEFUL_OPTIONS=STATEFUL_OPTIONS,
        FEATURES_TO_USE_OPTIONS=FEATURES_TO_USE_OPTIONS,
        MODEL_REGISTRY_DIR=MODEL_REGISTRY_DIR,
        MAX_HISTORY_ROWS=MAX_HISTORY_ROWS,
        get_run_hyperparameters=get_run_hyperparameters,
        get_ui_state=_get_ui_state,
        load_json_history=_load_json_history,
        save_json_history=_save_json_history,
        format_timestamp=_format_timestamp_iso_seconds,
        list_registry_models=_list_registry_models,
        promote_training_row=_promote_training_row,
    )

# --------------------------------------------------------------------------------------
# Tab 4: Backtest / Strategy - existing UI
# --------------------------------------------------------------------------------------
with tab_backtest:
    from src.ui.pages import backtest_page

    backtest_page.render_backtest_tab(
        st=st,
        pd=pd,
        plt=plt,
        os=os,
        cfg_mod=cfg_mod,
        MAX_HISTORY_ROWS=MAX_HISTORY_ROWS,
        get_predictions_csv_path=get_predictions_csv_path,
        generate_predictions_for_csv=generate_predictions_for_csv,
        load_strategy_defaults=_load_strategy_defaults,
        load_params_grid=_load_params_grid,
        save_params_grid=_save_params_grid,
        save_strategy_defaults_to_config=_save_strategy_defaults_to_config,
        run_backtest=_run_backtest,
        filter_backtest_history=_filter_backtest_history,
        filter_optimization_history=_filter_optimization_history,
        format_timestamp=_format_timestamp_iso_seconds,
        get_ui_state=_get_ui_state,
        load_json_history=_load_json_history,
        save_json_history=_save_json_history,
        start_optimization=_start_optimization,
        stop_optimization=_stop_optimization,
    )


# --------------------------------------------------------------------------------------
# Tab 5: Walk-Forward Analysis - train per fold OR robustness by parameter set
# --------------------------------------------------------------------------------------
with tab_walkforward:
    from src.ui.pages import walkforward_page

    walkforward_page.render_walkforward_tab(
        st=st,
        pd=pd,
        plt=plt,
        FREQUENCY=FREQUENCY,
        RESAMPLE_FREQUENCIES=RESAMPLE_FREQUENCIES,
        MAX_HISTORY_ROWS=MAX_HISTORY_ROWS,
        get_ui_state=_get_ui_state,
        load_strategy_defaults=_load_strategy_defaults,
        save_json_history=_save_json_history,
    )
